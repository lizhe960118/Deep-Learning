# 目标检测
## two stage:
### R-CNN
R-CNN的简要步骤如下：  
- (1) 输入测试图像
- (2) 利用选择性搜索Selective Search算法在图像中从下到上提取2000个左右的可能包含物体的候选区域Region Proposal
- (3) 因为取出的区域大小各自不同，所以需要将每个Region Proposal缩放（warp）成统一的227x227的大小并输入到CNN，将CNN的fc7层的输出作为特征
- (4) 将每个Region Proposal提取到的CNN特征输入到SVM进行分类
- (5) 使用回归器精细修正候选框位置：对于每一个类，训练一个线性回归模型去判定这个框是否框得完美。
### Fast/Faster R-CNN

### R-FCN

## one stage
### SSD
### YOLO
#### yolo-v1

# 图像分类
## VGGNet
堆叠多个小的卷积核而不使用池化操作可以增加网络的表征深度，同时限制参数的数量。
## ResNet
增加了神经网络架构的跳过连接（skip connection），使用批归一化并移除了作为最后一层的全连接层。
## DenseNet
当前层和前面所有层都相连接，concat
## GoogleNet（inception）
包含inception模块，通过构建由多个子模块组成的复杂卷积核来提高卷积核的学习能力和抽象能力
## suqeenet
## inception v2
增加正则化，5x5改成两个3x3
## Inception V3
inception V3把googlenet里一些7*7的卷积变成了1*7和7*1的两层串联，3*3的也一样，变成了1*3和3*1，
这样加速了计算，还增加了网络的非线性，减小过拟合的概率。另外，网络的输入从224改成了299.
使用小卷积，尝试使用非对称卷积通过执行批归一化和标签平滑化来改进正则化。标签平滑就是为每个类都分配一些权重，而不是将全权重分配给 ground truth 标签。
## inception V4
inception v4实际上是把原来的inception加上了resnet的方法，从一个节点能够跳过一些节点直接连入之后的一些节点，并且残差也跟着过去一个。 另外就是V4把一个先1*1再3*3那步换成了先3*3再1*1。论文说引入resnet不是用来提高深度，进而提高准确度的，只是用来提高速度的。


